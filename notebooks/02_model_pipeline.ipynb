{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c9d274",
   "metadata": {},
   "source": [
    "## Import custom modules and check structure\n",
    "\n",
    "We add the '../src' directory to the path to enable importing custom Python modules created for this project.  \n",
    "These include preprocessing functions, modeling utilities, and evaluation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_loading.py', 'evaluation.py', '__pycache__', 'preprocessing.py', 'modeling.py']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')  \n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../src\"))\n",
    "\n",
    "from preprocessing import create_aktywny_klient, encode_categorical, scale_data, scale_all_data\n",
    "from modeling import train_models, get_models\n",
    "from evaluation import evaluate_with_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load the cleaned customer data from the `data/raw/` directory using the `load_data` function.\n",
    "from data_loading import load_data\n",
    "df = load_data('../data/raw/Klienci_DB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d3dd4",
   "metadata": {},
   "source": [
    "## Preprocess and split the data\n",
    "\n",
    "- Add a new binary feature `aktywny_klient` (active client in the last 90 days).\n",
    "- Encode categorical variables (`plec`, `miasto`) using LabelEncoder and One-Hot Encoding.\n",
    "- Split the data into features `X` and target `y`.\n",
    "- Perform a stratified train/test split (80/20).\n",
    "- Scale both the train/test data separately and the full dataset for CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768836ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = create_aktywny_klient(df)\n",
    "df = encode_categorical(df)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['czy_churn'])\n",
    "y = df['czy_churn']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "X_scaled = scale_all_data(X) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904dd34",
   "metadata": {},
   "source": [
    "## Train models and evaluate on test set\n",
    "\n",
    "We train multiple models (`Random Forest`, `Gradient Boosting`, `Decision Tree`, `KNN`, `XGBoost`)  \n",
    "on the scaled training data and evaluate their performance on the test set using metrics like Accuracy, Precision, Recall, and F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e2fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Bosting</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>0.997583</td>\n",
       "      <td>0.997972</td>\n",
       "      <td>0.997777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.95030</td>\n",
       "      <td>0.965005</td>\n",
       "      <td>0.957176</td>\n",
       "      <td>0.961075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Accuracy  Precision    Recall  F1 Score\n",
       "0     Random Forest   1.00000   1.000000  1.000000  1.000000\n",
       "1  Gradient Bosting   1.00000   1.000000  1.000000  1.000000\n",
       "2     Decision Tree   1.00000   1.000000  1.000000  1.000000\n",
       "4           XGBoost   0.99715   0.997583  0.997972  0.997777\n",
       "3               KNN   0.95030   0.965005  0.957176  0.961075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and precision\n",
    "results_df = train_models(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d72be7",
   "metadata": {},
   "source": [
    "## Cross-Validation (5-fold)\n",
    "\n",
    "To ensure model stability and generalizability, we use 5-fold cross-validation  \n",
    "on the full scaled dataset and compare the mean F1 scores across all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962b1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model  Mean F1 (CV)   Std Dev\n",
      "0     Random Forest      1.000000  0.000000\n",
      "1  Gradient Bosting      1.000000  0.000000\n",
      "2     Decision Tree      1.000000  0.000000\n",
      "4           XGBoost      0.998659  0.000726\n",
      "3               KNN      0.958667  0.001186\n"
     ]
    }
   ],
   "source": [
    "cv_df =  evaluate_with_cv(get_models(), X_scaled, y)\n",
    "print(cv_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b834a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
